{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sketchRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rylnv1lTO1_xn2CpccoVJ0OjjWNHSdsg",
      "authorship_tag": "ABX9TyMd1K8CC7cG03zqU10dmWlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ij264/Corpus-Drawing-Project/blob/master/sketchRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AhiOqKusgTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "17cb3354-c65a-43d6-f807-d198f2b68235"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/f9/0626bbdb322e3a078d968e87e3b01341e7890544de891d0cb613641220e6/ipython-autotime-0.1.tar.bz2\n",
            "Building wheels for collected packages: ipython-autotime\n",
            "  Building wheel for ipython-autotime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-cp36-none-any.whl size=1831 sha256=053831fd4892284f819981e0bc51089489fe2a25444e42a6f65715b6094d1d56\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/df/81/2db1e54bc91002cec40334629bc39cfa86dff540b304ebcd6e\n",
            "Successfully built ipython-autotime\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVUsFa3YsqFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47c1c513-0eb9-4297-e8d0-c4445ea9754b"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.73 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhFbIJTVumIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db8848f7-99df-4a75-ea25-7d6482c0eb49"
      },
      "source": [
        "# parameters\n",
        "class HyperParameters():\n",
        "    def __init__(self):\n",
        "        self.location = '/content/drive/My Drive/Shared drives/Corpus Drawing Project/data/sketchrnn_airplane.npz'\n",
        "        self.Nz = 128\n",
        "        self.batch_size = 100\n",
        "        self.encoder_hidden_size = 256\n",
        "        self.decoder_hidden_size = 512\n",
        "        self.temperature = 0.9\n",
        "        self.gradient_clipping = 1.0\n",
        "        self.lr = 1e-4\n",
        "        self.KL_min = 0.2\n",
        "        self.R = 0.9999\n",
        "        self.WKL = 1.0\n",
        "        self.dropout_keep = 0.9\n",
        "\n",
        "hp = HyperParameters()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 11.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRXmS9EccF2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQEhcxKyZUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ade3280-6c34-409f-9b53-c4274ddba2f7"
      },
      "source": [
        "data = np.load(hp.location, encoding='latin1', allow_pickle=True)\n",
        "len(data['train'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "stream",
          "text": [
            "time: 609 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64eIhgf_tGXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder RNN\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        \n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "\n",
        "        # bidirectional LSTM \n",
        "        self.LSTM = nn.LSTM(input_size=5, # input vector is 5x1\n",
        "                            hp.encoder_hidden_size,\n",
        "                            hp.decoder_hidden_size,\n",
        "                            num_layers=1,\n",
        "                            bias=True,\n",
        "                            batch_first=False,\n",
        "                            bidirectional=True\n",
        "                            )\n",
        "        \n",
        "        self.mu = nn.Linear(in_features=hp.encoder_hidden_size,\n",
        "                            hp.Nz)\n",
        "        \n",
        "        self.sigma = nn.Linear(in_features=hp.encoder_hidden_size,\n",
        "                               hp.Nz)\n",
        "        \n",
        "        self.train()\n",
        "\n",
        "\n",
        "    def forward(self, inputs, batch_size, hidden_cell=None):\n",
        "        mu = self.mu(h)\n",
        "        sigma_hat = self.sigma(h)\n",
        "        sigma = torch.exp(sigma_hat/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFCUhifSszKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NN model: a bidirectional NN with LSTM\n",
        "class Model():\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # forward encoder\n",
        "        self.encoder() = EncoderRNN()\n",
        "\n",
        "        # backward encoder\n",
        "        self.decoder() = DecoderRNN()\n",
        "\n",
        "        # TODO: implement gradient clipping\n",
        "        self.encoder_optimiser() = optim.Adam(self.encoder.parameters(), lr=1e-4)\n",
        "        self.decoder_optimiser() = optim.Adam(self.decoder.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "    # bivariate normal distribution probability distribution function\n",
        "    def bivariate_normal_PDF(Dx, Dy):\n",
        "\n",
        "        z = (Dx - self.mu_x)**2/self.sigma_x**2 \\\n",
        "        - 2 * self.rho_xy * (Dx - self.mu_x) * (Dy - self.mu_y)/(self.sigma_x * self.sigma_y) \\\n",
        "        + (Dy - self.mu_y)**2/self.sigma_y**2\n",
        "\n",
        "        prefactor = 1/(2 * np.pi * self.sigma_x * self.sigma_y * torch.sqrt(1-self.rho_xy**2))\n",
        "\n",
        "        return prefactor * torch.exp(-z/(2 * (1 - self.rho_xy**2)))\n",
        "\n",
        "\n",
        "    #Â reconstruction loss\n",
        "    def LR(self, Dx, Dy, p):\n",
        "\n",
        "        PDF = bivariate_normal_PDF(Dx, Dy)\n",
        "\n",
        "        LS = -1/float(N_max) * torch.sum(\n",
        "            torch.log(\n",
        "                torch.sum(self.Pi * PDF)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        LP = -1/float(N_max) * torch.sum(\n",
        "            p * torch.log(self.q)\n",
        "        )\n",
        "\n",
        "        return LS + LP\n",
        "\n",
        "    def KL(self, Dx, Dy):\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}